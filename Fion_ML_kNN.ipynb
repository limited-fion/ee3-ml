{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limited-fion/ee3-ml/blob/main/Fion_ML_kNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b6fcf2",
      "metadata": {
        "id": "30b6fcf2"
      },
      "source": [
        "# k-nearest neighbour (k-NN)\n",
        "\n",
        "The k-nearest neighbour algorithm (k-NN) is a supervised machine learning algorithm, which can be used for both classification and regression. The core principle of this algorithm is that the label of a point can be deduced by considering nearby points with known labels. Specifically, the algorithm considers the k points which are nearest to the query point in the feature space. Several different distance measures can be used to identify the nearest neighbours, with common choices being the Euclidean or Hamming distance. Moreover, the value of k must be selected by the user. For instance, if we want to classify an unknown point (?) according to the two classes △ and □ as illustrated in the feature space of the figure below. If k is selected to be 1, the output of the unknown data sample will be simply assigned to the class of its nearest neighbour (in this case △ ). While if k is selected to be 3, the data sample will be labelled according to the dominant class in the range of 3 nearest neighbours (in this example it will be □). Several advantages can be observed in using this classifier such as not needing an explicit training step and the fact that information present in the training instances is never lost (because the instances themselves are stored explicitly). However, many disadvantages can be found in this classifier as well, such as the potentially high cost of classifying new targets. This is because nearly all the computation takes place at classification time rather than during a training process. A second disadvantage is that the entire training set must be considered during the classification process, which requires large memory capabilities. Finally, as we have seen, this classifier is highly biased by the value of k selected.\n",
        "\n",
        "![knn.gif](data:image/gif;base64,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)\n",
        "\n",
        "In this tutorial, we will investigate using k-NN classifier on the Iris-datset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib import font_manager as fm, pyplot as plt\n",
        "\n",
        "!wget https://github.com/trishume/OpenTuringCompiler/blob/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf\n",
        "!wget https://github.com/matomo-org/travis-scripts/blob/master/fonts/Arial.ttf \n",
        "\n",
        "font_files = fm.findSystemFonts()\n",
        "\n",
        "# Go through and add each to Matplotlib's font cache.\n",
        "for font_file in font_files:\n",
        "    fm.fontManager.addfont(font_file)\n",
        "\n",
        "fm.fontManager.ttflist += fm.createFontList(['Times New Roman.ttf'])\n",
        "\n",
        "# Use your new font on all your plots.\n",
        "plt.rc('font', family='serif')"
      ],
      "metadata": {
        "id": "_o5hRn2wE2GR",
        "outputId": "df7bbce6-f9d5-40da-edc2-913a84a1e323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_o5hRn2wE2GR",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-22 02:05:33--  https://github.com/trishume/OpenTuringCompiler/blob/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘Times New Roman.ttf’\n",
            "\n",
            "Times New Roman.ttf     [ <=>                ] 138.90K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-11-22 02:05:34 (1.86 MB/s) - ‘Times New Roman.ttf’ saved [142229]\n",
            "\n",
            "--2022-11-22 02:05:34--  https://github.com/matomo-org/travis-scripts/blob/master/fonts/Arial.ttf\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘Arial.ttf’\n",
            "\n",
            "Arial.ttf               [ <=>                ] 139.90K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-11-22 02:05:34 (1.83 MB/s) - ‘Arial.ttf’ saved [143255]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: MatplotlibDeprecationWarning: \n",
            "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8b8f49b9",
      "metadata": {
        "id": "8b8f49b9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.colors as colors\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9db05c52",
      "metadata": {
        "id": "9db05c52"
      },
      "outputs": [],
      "source": [
        "iris_data = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f6a1b595",
      "metadata": {
        "id": "f6a1b595"
      },
      "outputs": [],
      "source": [
        "# Function to divide the data into training and testing\n",
        "\n",
        "import random\n",
        "random.seed(22)\n",
        "def separate_data():\n",
        "    train_A = iris_dataset[0:40]\n",
        "    test_A = iris_dataset[40:50]\n",
        "    train_B = iris_dataset[50:90]\n",
        "    test_B = iris_dataset[90:100]\n",
        "    train_C = iris_dataset[100:140]\n",
        "    test_C = iris_dataset[140:150]\n",
        "    train = np.concatenate((train_A,train_B,train_C))\n",
        "    test =  np.concatenate((test_A,test_B,test_C))\n",
        "    return train,test\n",
        "\n",
        "iris_dataset = np.column_stack((iris_data.data,iris_data.target.T)) #Join X and Y\n",
        "iris_dataset = list(iris_dataset)\n",
        "random.shuffle(iris_dataset)\n",
        "\n",
        "Filetrain, Filetest = separate_data()\n",
        "\n",
        "X_train = np.array([i[:4] for i in Filetrain])\n",
        "y_train = np.array([i[4] for i in Filetrain])\n",
        "X_test = np.array([i[:4] for i in Filetest])\n",
        "y_test = np.array([i[4] for i in Filetest])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "06b3c2e0",
      "metadata": {
        "id": "06b3c2e0"
      },
      "outputs": [],
      "source": [
        "def distance(p1, p2):\n",
        "    squared_difference = 0.0\n",
        "    for i in range(len(p1)):\n",
        "        squared_difference += (p1[i] - p2[i])**2\n",
        "    final_distance = squared_difference ** 0.5\n",
        "    return final_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "acc8422c",
      "metadata": {
        "id": "acc8422c"
      },
      "outputs": [],
      "source": [
        "def fit(test_sample, training_set, training_labels, k):\n",
        "    \n",
        "    distances = []\n",
        "    \n",
        "    # Computing the distances for all data points with respect to test sample     \n",
        "    \n",
        "    for i in range(len(training_set)):\n",
        "        distance_to_point = distance(test_sample, training_set[i])\n",
        "        distances.append([distance_to_point, training_set[i], training_labels[i]])\n",
        "    # sort the distances\n",
        "    distances.sort(key = lambda x : x[0])\n",
        "    \n",
        "    # Find the k nearest neighbours according to the distances\n",
        "    k_nearest_neighbours = distances[0:k]\n",
        "    \n",
        "    # Getting class with majority voting     \n",
        "    label_counts = {}\n",
        "    for i in range(0, k):\n",
        "        closest_label = k_nearest_neighbours[i][2]\n",
        "\n",
        "        if (closest_label in label_counts) == True:\n",
        "            label_counts[closest_label] += 1\n",
        "        else:\n",
        "            label_counts[closest_label] = 1\n",
        "       \n",
        "    labelCounts = list(label_counts.values())\n",
        "    classes = list(label_counts.keys())\n",
        "    y_pred = classes[labelCounts.index(max(labelCounts))]\n",
        "    \n",
        "    return (k_nearest_neighbours, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fd35f32f",
      "metadata": {
        "id": "fd35f32f",
        "outputId": "4d5b586e-8bda-4b70-f48d-b4bbcd1bb09f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sample predictions for k = 3 \t\n",
            "*********************************\n",
            "test sample: [5.1 3.8 1.9 0.4] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.3 2.3 4.4 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.5 3.  5.5 1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.7 2.5 5.8 1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.2 2.9 4.3 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [7.2 3.2 6.  1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.4 2.9 1.4 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.1 2.9 4.7 1.4] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [7.1 3.  5.9 2.1] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.7 3.2 1.3 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.7 3.  5.2 2.3] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.3 2.5 4.9 1.5] \t predicted label: 2.0 \t true label: 1.0 \t Misclassified\n",
            "test sample: [6.  2.2 5.  1.5] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [7.9 3.8 6.4 2. ] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [5.4 3.  4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.9 3.2 5.7 2.3] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.9 3.1 4.9 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.6 3.  4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.5 3.5 1.3 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.6 2.9 3.6 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.2 2.2 4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.2 2.7 3.9 1.4] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.4 3.4 1.7 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.6 3.  4.1 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [4.8 3.1 1.6 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [4.6 3.2 1.4 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.8 2.8 5.1 2.4] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.6 3.4 1.4 0.3] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.  2.2 4.  1. ] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.  3.2 1.2 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n"
          ]
        }
      ],
      "source": [
        "k = 3\n",
        "print(f'Test sample predictions for k = {k} \\t')\n",
        "print('*********************************')\n",
        "for i in range(len(X_test)):\n",
        "    neighbours, pred_label = fit(X_test[i], X_train, y_train, k)\n",
        "    if (pred_label == y_test[i]):\n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Correctly classified\")\n",
        "    else:\n",
        "        \n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Misclassified\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7615b203",
      "metadata": {
        "id": "7615b203"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred_label, true_label):\n",
        "    TP = 0\n",
        "    for i in range(len(pred_label)):\n",
        "        if(pred_label[i] == true_label[i]):\n",
        "            TP += 1\n",
        "    \n",
        "    accuracy = (TP / len(pred_label))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cfba8e83",
      "metadata": {
        "id": "cfba8e83",
        "outputId": "74f3f33b-71a0-449b-e4f7-93675f6a98fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k = 1, Accuracy 93.33333333333333 %\n",
            "For k = 3, Accuracy 96.66666666666667 %\n",
            "For k = 5, Accuracy 96.66666666666667 %\n",
            "For k = 7, Accuracy 96.66666666666667 %\n",
            "For k = 9, Accuracy 96.66666666666667 %\n",
            "For k = 11, Accuracy 96.66666666666667 %\n",
            "For k = 13, Accuracy 100.0 %\n",
            "For k = 15, Accuracy 100.0 %\n",
            "For k = 17, Accuracy 96.66666666666667 %\n",
            "For k = 19, Accuracy 96.66666666666667 %\n",
            "For k = 21, Accuracy 96.66666666666667 %\n",
            "For k = 23, Accuracy 96.66666666666667 %\n",
            "For k = 25, Accuracy 96.66666666666667 %\n",
            "For k = 27, Accuracy 96.66666666666667 %\n",
            "For k = 29, Accuracy 96.66666666666667 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "accuracy_list = []\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "\n",
        "for k in k_list:\n",
        "    y_pred = []\n",
        "    for test_instance in X_test:\n",
        "        neighbours, pred_label = fit(test_instance, X_train, y_train, k)\n",
        "        y_pred.append(pred_label)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    print(\"For k = {}, Accuracy {} %\".format(k,acc*100))\n",
        "    \n",
        "    accuracy_list.append(acc)\n",
        "plt.plot(k_list, accuracy_list)  \n",
        "\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('k vs Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dd775c7b",
      "metadata": {
        "id": "dd775c7b"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# Create color maps\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
        "\n",
        "def decision_boundary(k):\n",
        "    # For better data visulaisation we considered the first two features (petal length and sepal length) \n",
        "    # in the decision boundary plot.\n",
        "    X = np.concatenate((X_train, X_test))\n",
        "    X = X[:, :2]\n",
        "    y = np.concatenate((y_train, y_test))\n",
        "    \n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    Z = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    y_preds = []\n",
        "\n",
        "    for item in Z:\n",
        "        neighbours, pred_label = fit(item, X, y, k)\n",
        "        y_preds.append(pred_label)\n",
        "        \n",
        "     # Put the result into a color plot\n",
        "    y_preds = np.asarray(y_preds)\n",
        "    y_preds = y_preds.reshape(xx.shape)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.pcolormesh(xx, yy, y_preds, cmap=cmap_light)\n",
        "    \n",
        "    # Plot also the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\"Decision boundary for k = {0}\".format(k))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0f3066cb",
      "metadata": {
        "scrolled": false,
        "id": "0f3066cb",
        "outputId": "281146df-8b78-47e9-e2c1-d822eff078b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fd2977b99923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This code may take several minutes to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdecision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-63cbd52608f4>\u001b[0m in \u001b[0;36mdecision_boundary\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mneighbours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-11d0b5372898>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(test_sample, training_set, training_labels, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdistance_to_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistance_to_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# sort the distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d14d86e5a4f3>\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(p1, p2)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msquared_difference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msquared_difference\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfinal_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquared_difference\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# This code may take several minutes to finish\n",
        "for k in k_list:\n",
        "    decision_boundary(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da219de2",
      "metadata": {
        "id": "da219de2"
      },
      "source": [
        "# Coursework:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e957e3",
      "metadata": {
        "id": "14e957e3"
      },
      "source": [
        "## Task 1:\n",
        "\n",
        "In the previous exercise, Euclidean distance was used to measure the distance between test sample and its neighbours. Use Minkowski (use p value of 3) and Manhattan distances instead and observe the difference in results. In your report:\n",
        "\n",
        "- Include the codes you used in estimating Minkowski and Manhattan distances.\n",
        "- Use the same k values in the previous code for the new distances to get the accuracy.\n",
        "- Use a table to compare the accuracy for each distance measure and k value and include that in your report.\n",
        "- Discuss your results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def minkowski_distance(p1, p2):\n",
        "    p = 3\n",
        "    difference_p = 0.0\n",
        "    for i in range(len(p1)):\n",
        "        difference_p += np.abs(p1[i] - p2[i])**p\n",
        "    final_distance = difference_p ** (1/p)\n",
        "    return final_distance"
      ],
      "metadata": {
        "id": "f96Nt2XEFPbp"
      },
      "id": "f96Nt2XEFPbp",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_minkowski_dist(test_sample, training_set, training_labels, k):\n",
        "    \n",
        "    distances = []\n",
        "    \n",
        "    # Computing the distances for all data points with respect to test sample     \n",
        "    \n",
        "    for i in range(len(training_set)):\n",
        "        distance_to_point = minkowski_distance(test_sample, training_set[i])\n",
        "        distances.append([distance_to_point, training_set[i], training_labels[i]])\n",
        "    # sort the distances\n",
        "    distances.sort(key = lambda x : x[0])\n",
        "    \n",
        "    # Find the k nearest neighbours according to the distances\n",
        "    k_nearest_neighbours = distances[0:k]\n",
        "    \n",
        "    # Getting class with majority voting     \n",
        "    label_counts = {}\n",
        "    for i in range(0, k):\n",
        "        closest_label = k_nearest_neighbours[i][2]\n",
        "\n",
        "        if (closest_label in label_counts) == True:\n",
        "            label_counts[closest_label] += 1\n",
        "        else:\n",
        "            label_counts[closest_label] = 1\n",
        "       \n",
        "    labelCounts = list(label_counts.values())\n",
        "    classes = list(label_counts.keys())\n",
        "    y_pred = classes[labelCounts.index(max(labelCounts))]\n",
        "    \n",
        "    return (k_nearest_neighbours, y_pred)"
      ],
      "metadata": {
        "id": "WlRzU1ozHwUX"
      },
      "id": "WlRzU1ozHwUX",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "print(f'Test sample predictions for k = {k} \\t')\n",
        "print('*********************************')\n",
        "for i in range(len(X_test)):\n",
        "    neighbours, pred_label = fit_minkowski_dist(X_test[i], X_train, y_train, k)\n",
        "    if (pred_label == y_test[i]):\n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Correctly classified\")\n",
        "    else:\n",
        "        \n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Misclassified\")"
      ],
      "metadata": {
        "id": "YJq6nza9Hh6u",
        "outputId": "75bb6c86-1db0-4cbb-ad30-f00b6a294bc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YJq6nza9Hh6u",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sample predictions for k = 3 \t\n",
            "*********************************\n",
            "test sample: [5.1 3.8 1.9 0.4] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.3 2.3 4.4 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.5 3.  5.5 1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.7 2.5 5.8 1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.2 2.9 4.3 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [7.2 3.2 6.  1.8] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.4 2.9 1.4 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.1 2.9 4.7 1.4] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [7.1 3.  5.9 2.1] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.7 3.2 1.3 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.7 3.  5.2 2.3] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.3 2.5 4.9 1.5] \t predicted label: 2.0 \t true label: 1.0 \t Misclassified\n",
            "test sample: [6.  2.2 5.  1.5] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [7.9 3.8 6.4 2. ] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [5.4 3.  4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.9 3.2 5.7 2.3] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [6.9 3.1 4.9 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.6 3.  4.5 1.5] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.5 3.5 1.3 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.6 2.9 3.6 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [6.2 2.2 4.5 1.5] \t predicted label: 2.0 \t true label: 1.0 \t Misclassified\n",
            "test sample: [5.2 2.7 3.9 1.4] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.4 3.4 1.7 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.6 3.  4.1 1.3] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [4.8 3.1 1.6 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [4.6 3.2 1.4 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [5.8 2.8 5.1 2.4] \t predicted label: 2.0 \t true label: 2.0 \t Correctly classified\n",
            "test sample: [4.6 3.4 1.4 0.3] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n",
            "test sample: [6.  2.2 4.  1. ] \t predicted label: 1.0 \t true label: 1.0 \t Correctly classified\n",
            "test sample: [5.  3.2 1.2 0.2] \t predicted label: 0.0 \t true label: 0.0 \t Correctly classified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_list = []\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "\n",
        "for k in k_list:\n",
        "    y_pred = []\n",
        "    for test_instance in X_test:\n",
        "        neighbours, pred_label = fit_minkowski_dist(test_instance, X_train, y_train, k)\n",
        "        y_pred.append(pred_label)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    print(\"For k = {}, Accuracy {} %\".format(k,acc*100))\n",
        "    \n",
        "    accuracy_list.append(acc)\n",
        "plt.plot(k_list, accuracy_list)  \n",
        "\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('k vs Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uObY7bivID8g"
      },
      "id": "uObY7bivID8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manhattan_distance(p1, p2):\n",
        "    difference = 0.0\n",
        "    for i in range(len(p1)):\n",
        "        difference += np.abs(p1[i] - p2[i])\n",
        "    final_distance = difference\n",
        "    return final_distance"
      ],
      "metadata": {
        "id": "509N-fXBILJ2"
      },
      "id": "509N-fXBILJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_manhattan_dist(test_sample, training_set, training_labels, k):\n",
        "    \n",
        "    distances = []\n",
        "    \n",
        "    # Computing the distances for all data points with respect to test sample     \n",
        "    \n",
        "    for i in range(len(training_set)):\n",
        "        distance_to_point = manhattan_distance(test_sample, training_set[i])\n",
        "        distances.append([distance_to_point, training_set[i], training_labels[i]])\n",
        "    # sort the distances\n",
        "    distances.sort(key = lambda x : x[0])\n",
        "    \n",
        "    # Find the k nearest neighbours according to the distances\n",
        "    k_nearest_neighbours = distances[0:k]\n",
        "    \n",
        "    # Getting class with majority voting     \n",
        "    label_counts = {}\n",
        "    for i in range(0, k):\n",
        "        closest_label = k_nearest_neighbours[i][2]\n",
        "\n",
        "        if (closest_label in label_counts) == True:\n",
        "            label_counts[closest_label] += 1\n",
        "        else:\n",
        "            label_counts[closest_label] = 1\n",
        "       \n",
        "    labelCounts = list(label_counts.values())\n",
        "    classes = list(label_counts.keys())\n",
        "    y_pred = classes[labelCounts.index(max(labelCounts))]\n",
        "    \n",
        "    return (k_nearest_neighbours, y_pred)"
      ],
      "metadata": {
        "id": "s_i_yvZxIooN"
      },
      "id": "s_i_yvZxIooN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "print(f'Test sample predictions for k = {k} \\t')\n",
        "print('*********************************')\n",
        "for i in range(len(X_test)):\n",
        "    neighbours, pred_label = fit_manhattan_dist(X_test[i], X_train, y_train, k)\n",
        "    if (pred_label == y_test[i]):\n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Correctly classified\")\n",
        "    else:\n",
        "        \n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Misclassified\")"
      ],
      "metadata": {
        "id": "SnBDGMJtIlF-"
      },
      "id": "SnBDGMJtIlF-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_list = []\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "\n",
        "for k in k_list:\n",
        "    y_pred = []\n",
        "    for test_instance in X_test:\n",
        "        neighbours, pred_label = fit_manhattan_dist(test_instance, X_train, y_train, k)\n",
        "        y_pred.append(pred_label)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    print(\"For k = {}, Accuracy {} %\".format(k,acc*100))\n",
        "    \n",
        "    accuracy_list.append(acc)\n",
        "plt.plot(k_list, accuracy_list)  \n",
        "\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('k vs Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jru81sWIIv2G"
      },
      "id": "jru81sWIIv2G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f92bd2ab",
      "metadata": {
        "id": "f92bd2ab"
      },
      "source": [
        "## Task 2:\n",
        "\n",
        "Write a code using scikit-learn to do the same procedure in the tutorial and repeat Task 1 with scikitlearn. In your report:\n",
        "\n",
        "- Include your code.\n",
        "- Table for comparing the results as in Task 1.\n",
        "\n",
        "Useful links:\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "- https://scikit-learn.org/0.24/modules/generated/sklearn.neighbors.DistanceMetric.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "\n",
        "\n",
        "\n",
        "# manhattan -> 1, euclidean -> 2, minkowski -> 3\n",
        "\n",
        "distance_p = [1,2,3]\n",
        "\n",
        "\n",
        "\n",
        "accuracy_lists = [[],[],[]]\n",
        "\n",
        "\n",
        "\n",
        "for (i,p) in enumerate(distance_p):\n",
        "\n",
        "  for k in k_list:\n",
        "\n",
        "    classifier = KNeighborsClassifier(k, weights = 'uniform', p = p, metric = 'minkowski')\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "\n",
        "    # print(\"For k = {}, Accuracy {} %\".format(k, round(acc, 4)*100))\n",
        "\n",
        "    accuracy_lists[i].append(round(acc,4)*100)\n",
        "\n",
        "   \n",
        "\n",
        "for (k, manhattan_accuracy_scikit, euclidean_accuracy_scikit, minkowski_accuracy_scikit) in zip(k_list, accuracy_lists[0], accuracy_lists[1], accuracy_lists[2]):\n",
        "\n",
        "  print(\"{} & {} & {} & {} \\\\\\\\\".format(k, euclidean_accuracy_scikit, minkowski_accuracy_scikit, manhattan_accuracy_scikit))"
      ],
      "metadata": {
        "id": "INyhnCB5ha65",
        "outputId": "4b7738f9-99c1-4e69-8c8c-dae1887888dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "INyhnCB5ha65",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 & 93.33 & 93.33 & 93.33 \\\\\n",
            "3 & 96.67 & 93.33 & 96.67 \\\\\n",
            "5 & 96.67 & 93.33 & 96.67 \\\\\n",
            "7 & 96.67 & 96.67 & 96.67 \\\\\n",
            "9 & 96.67 & 96.67 & 96.67 \\\\\n",
            "11 & 96.67 & 100.0 & 96.67 \\\\\n",
            "13 & 100.0 & 100.0 & 96.67 \\\\\n",
            "15 & 100.0 & 100.0 & 96.67 \\\\\n",
            "17 & 96.67 & 96.67 & 96.67 \\\\\n",
            "19 & 96.67 & 96.67 & 100.0 \\\\\n",
            "21 & 96.67 & 96.67 & 100.0 \\\\\n",
            "23 & 96.67 & 96.67 & 96.67 \\\\\n",
            "25 & 96.67 & 96.67 & 96.67 \\\\\n",
            "27 & 96.67 & 96.67 & 96.67 \\\\\n",
            "29 & 96.67 & 96.67 & 93.33 \\\\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import DistanceMetric\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "e25PtxGAc0_W"
      },
      "id": "e25PtxGAc0_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dist = DistanceMetric.get_metric('euclidean')\n",
        "\n",
        "for k in k_list:\n",
        "  neigh = KNeighborsClassifier(n_neighbors=k, metric='euclidean') \n",
        "  neigh.fit(X_train, y_train)\n",
        "  print(\"k = \", k, \"accuracy: \", neigh.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "Ny3lEaweqqQl"
      },
      "id": "Ny3lEaweqqQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in k_list:\n",
        "  neigh = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
        "  neigh.fit(X_train, y_train)\n",
        "  print(\"k = \", k, \"accuracy: \", neigh.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "zUPX5WpXcPRv"
      },
      "id": "zUPX5WpXcPRv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dist = DistanceMetric.get_metric('minkowski')\n",
        "\n",
        "for k in k_list:\n",
        "  neigh = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=3)\n",
        "  neigh.fit(X_train, y_train)\n",
        "  print(\"k = \", k, \"accuracy: \", neigh.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "db_D0wE-qtOk"
      },
      "id": "db_D0wE-qtOk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for k in k_list:\n",
        "#   neigh = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=1)\n",
        "#   neigh.fit(X_train, y_train)\n",
        "#   print(\"k = \", k, \"accuracy: \", neigh.score(X_test, y_test))\n",
        "\n",
        "for k in k_list:\n",
        "    y_pred = []\n",
        "    neigh = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=1)\n",
        "    neigh.fit(X_train, y_train)\n",
        "    y_pred = neigh.predict(X_test)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    print(\"For k = {}, Accuracy {} %\".format(k,acc*100))"
      ],
      "metadata": {
        "id": "Vx3m9MmIcF3G"
      },
      "id": "Vx3m9MmIcF3G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# Create color maps\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
        "\n",
        "def decision_boundary(k):\n",
        "    # For better data visulaisation we considered the first two features (petal length and sepal length) \n",
        "    # in the decision boundary plot.\n",
        "    X = np.concatenate((X_train, X_test))\n",
        "    X = X[:, :2]\n",
        "    y = np.concatenate((y_train, y_test))\n",
        "    \n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    Z = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    y_preds = []\n",
        "\n",
        "    for item in Z:\n",
        "        neigh.fit(X_train, y_train)\n",
        "        y_preds = neigh.predict(X_test)\n",
        "        \n",
        "     # Put the result into a color plot\n",
        "    y_preds = np.asarray(y_preds)\n",
        "    y_preds = y_preds.reshape(xx.shape)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.pcolormesh(xx, yy, y_preds, cmap=cmap_light)\n",
        "    \n",
        "    # Plot also the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\"Decision boundary for k = {0}\".format(k))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AaDaoWHdfiEM"
      },
      "id": "AaDaoWHdfiEM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 17\n",
        "decision_boundary(k)"
      ],
      "metadata": {
        "id": "jxv19z0nfZZb"
      },
      "id": "jxv19z0nfZZb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in k_list:\n",
        "  neigh = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
        "  neigh.fit(X_train, y_train)\n",
        "  print(\"k = \", k, \"accuracy: \", neigh.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "0cnQy_nEIz-t"
      },
      "id": "0cnQy_nEIz-t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3:\n",
        "\n",
        "Consider the original code again of this tutorial using Eculidean distance. Seperate you training points into two equal subsets and repeat the steps on the tutorial for each subset. Report your observations in terms of the test accuray for the two subsets compared with the original data."
      ],
      "metadata": {
        "id": "Q1a2-Dc6vaj3"
      },
      "id": "Q1a2-Dc6vaj3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to divide the data into training and testing\n",
        "\n",
        "import random\n",
        "random.seed(22)\n",
        "def separate_data_t2():\n",
        "    train_A = iris_dataset[0:25]\n",
        "    test_A = iris_dataset[25:50]\n",
        "    train_B = iris_dataset[50:75]\n",
        "    test_B = iris_dataset[75:100]\n",
        "    train_C = iris_dataset[100:125]\n",
        "    test_C = iris_dataset[125:150]\n",
        "    train = np.concatenate((train_A,train_B,train_C))\n",
        "    test =  np.concatenate((test_A,test_B,test_C))\n",
        "    return train,test\n",
        "\n",
        "iris_dataset = np.column_stack((iris_data.data,iris_data.target.T)) #Join X and Y\n",
        "iris_dataset = list(iris_dataset)\n",
        "random.shuffle(iris_dataset)\n",
        "\n",
        "Filetrain, Filetest = separate_data_t2()\n",
        "\n",
        "X_train = np.array([i[:4] for i in Filetrain])\n",
        "y_train = np.array([i[4] for i in Filetrain])\n",
        "X_test = np.array([i[:4] for i in Filetest])\n",
        "y_test = np.array([i[4] for i in Filetest])"
      ],
      "metadata": {
        "id": "-PhcTqZxai1A"
      },
      "id": "-PhcTqZxai1A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "print(f'Test sample predictions for k = {k} \\t')\n",
        "print('*********************************')\n",
        "for i in range(len(X_test)):\n",
        "    neighbours, pred_label = fit(X_test[i], X_train, y_train, k)\n",
        "    if (pred_label == y_test[i]):\n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Correctly classified\")\n",
        "    else:\n",
        "        \n",
        "        print(f'test sample: {X_test[i]} \\t', \n",
        "          f'predicted label: {pred_label} \\t', f'true label: {y_test[i]} \\t', \"Misclassified\")"
      ],
      "metadata": {
        "id": "TwIgjJWPbfbn"
      },
      "id": "TwIgjJWPbfbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_list = []\n",
        "k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
        "\n",
        "for k in k_list:\n",
        "    y_pred = []\n",
        "    for test_instance in X_test:\n",
        "        neighbours, pred_label = fit(test_instance, X_train, y_train, k)\n",
        "        y_pred.append(pred_label)\n",
        "    acc = accuracy(y_pred, y_test)\n",
        "    print(\"For k = {}, Accuracy {} %\".format(k,acc*100))\n",
        "    \n",
        "    accuracy_list.append(acc)\n",
        "plt.plot(k_list, accuracy_list)  \n",
        "\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('k vs Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0yI4jDkSj-hJ"
      },
      "id": "0yI4jDkSj-hJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure()\n",
        "f.set_figwidth(10)\n",
        "f.set_figheight(5)\n",
        "\n",
        "a = np.linspace(-20,10,100000)\n",
        "b = 0.5*a-5\n",
        "c = np.linspace(10,20,100000)\n",
        "d = 20*c -200\n",
        "ax = plt.plot(a, b, color='blue')  \n",
        "ax = plt.plot(c, d, color='blue',label='maxout')  \n",
        "ax = plt.plot(a, np.ones(100000)*0.5, color='red', label='derivative')  \n",
        "ax = plt.plot(c, np.ones(100000)*20, color='red')  \n",
        "plt.grid('both')\n",
        "plt.ylim([-20,60])\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('s')"
      ],
      "metadata": {
        "id": "jTUUBmVcTO4m",
        "outputId": "09420ed2-69e8-4242-9100-bafdb6e5d145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "id": "jTUUBmVcTO4m",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 's')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|"
      ],
      "metadata": {
        "id": "JpukJseUFS6C"
      },
      "id": "JpukJseUFS6C",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}